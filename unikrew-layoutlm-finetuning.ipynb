{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13300037,"sourceType":"datasetVersion","datasetId":8430023}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U transformers\n!pip install -U datasets evaluate seqeval pillow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:13:44.166159Z","iopub.execute_input":"2025-10-14T18:13:44.166743Z","iopub.status.idle":"2025-10-14T18:14:17.403402Z","shell.execute_reply.started":"2025-10-14T18:13:44.166718Z","shell.execute_reply":"2025-10-14T18:14:17.402347Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nCollecting transformers\n  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.19.1)\nCollecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.35.3 tokenizers-0.22.1 transformers-4.57.1\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.1.1)\nCollecting datasets\n  Downloading datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.3.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.19.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nCollecting pyarrow>=21.0.0 (from datasets)\n  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\nRequirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.35.3)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.3)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.8.3)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading datasets-4.2.0-py3-none-any.whl (506 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.3/506.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=af863b44f9205907b69d6203ff737f20caf5c238f35eaaedecdc730eb00b7b98\n  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\nSuccessfully built seqeval\nInstalling collected packages: pyarrow, datasets, seqeval, evaluate\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 4.1.1\n    Uninstalling datasets-4.1.1:\n      Successfully uninstalled datasets-4.1.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-4.2.0 evaluate-0.4.6 pyarrow-21.0.0 seqeval-1.2.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os, json\nfrom pathlib import Path\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:14:17.405048Z","iopub.execute_input":"2025-10-14T18:14:17.405311Z","iopub.status.idle":"2025-10-14T18:14:17.409692Z","shell.execute_reply.started":"2025-10-14T18:14:17.405288Z","shell.execute_reply":"2025-10-14T18:14:17.408883Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def parse_boxes(file_path):\n    words, boxes = [], []\n    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n        for line in f:\n            parts = line.strip().split(\",\", 8)\n            if len(parts) < 9:\n                continue\n            x0,y0,x1,y1,x2,y2,x3,y3 = map(int, parts[:8])\n            text = parts[8].strip()\n            words.append(text)\n            boxes.append([min(x0,x2), min(y0,y2), max(x1,x3), max(y1,y3)])\n    return words, boxes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:14:17.410553Z","iopub.execute_input":"2025-10-14T18:14:17.410756Z","iopub.status.idle":"2025-10-14T18:14:17.429684Z","shell.execute_reply.started":"2025-10-14T18:14:17.410742Z","shell.execute_reply":"2025-10-14T18:14:17.428856Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def normalize_boxes(boxes, width, height):\n    norm = []\n    for x0,y0,x1,y1 in boxes:\n        norm.append([\n            int(1000 * x0 / width),\n            int(1000 * y0 / height),\n            int(1000 * x1 / width),\n            int(1000 * y1 / height)\n        ])\n    return norm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:14:17.431559Z","iopub.execute_input":"2025-10-14T18:14:17.431874Z","iopub.status.idle":"2025-10-14T18:14:17.447037Z","shell.execute_reply.started":"2025-10-14T18:14:17.431856Z","shell.execute_reply":"2025-10-14T18:14:17.446330Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def make_jsonl(split_dir, out_file):\n    img_dir = Path(split_dir) / \"img\"\n    box_dir = Path(split_dir) / \"box\"\n    ent_dir = Path(split_dir) / \"entities\"\n    out = []\n    for img_path in img_dir.iterdir():\n        base = img_path.stem\n        box_path = box_dir / f\"{base}.txt\"\n        ent_path = ent_dir / f\"{base}.txt\"\n        if not box_path.exists() or not ent_path.exists():\n            continue\n\n        words, boxes = parse_boxes(box_path)\n        width, height = Image.open(img_path).size\n        boxes = normalize_boxes(boxes, width, height)\n        labels = [\"O\"] * len(words)\n\n        entities = json.load(open(ent_path))\n        for key, value in entities.items():\n            entity_tokens = value.replace(\",\", \" \").split()\n            entity_tokens = [t for t in entity_tokens if t.strip()]\n            if not entity_tokens:\n                continue\n                \n            for i, w in enumerate(words):\n                w_tokens = w.replace(\",\", \" \").split()\n                w_tokens = [t for t in w_tokens if t.strip()]\n                if not w_tokens:\n                    continue\n                    \n                overlap = len(set(w_tokens) & set(entity_tokens))\n                if overlap >= max(1, len(entity_tokens) // 2):\n                    labels[i] = f\"B-{key.upper()}\"\n\n        first_found_company = False\n        first_found_address = False\n        \n        for i in labels:\n            if i == \"B-COMPANY\" and first_found_company:\n                labels[i] = \"I-COMPANY\"\n            if i == \"B-ADDRESS\" and first_found_address:\n                labels[i] = \"I-ADDRESS\"\n\n        out.append({\n            \"id\": base,\n            \"image\": str(img_path),\n            \"words\": words,\n            \"boxes\": boxes,\n            \"labels\": labels\n        })\n\n    with open(out_file, \"w\") as f:\n        for item in out:\n            f.write(json.dumps(item) + \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:14:17.447897Z","iopub.execute_input":"2025-10-14T18:14:17.448169Z","iopub.status.idle":"2025-10-14T18:14:17.465640Z","shell.execute_reply.started":"2025-10-14T18:14:17.448146Z","shell.execute_reply":"2025-10-14T18:14:17.464885Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"make_jsonl(\"/kaggle/input/recipts-data/dataset/train\", \"/kaggle/working/train.jsonl\")\nmake_jsonl(\"/kaggle/input/recipts-data/dataset/test\", \"/kaggle/working/test.jsonl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:14:17.466385Z","iopub.execute_input":"2025-10-14T18:14:17.466744Z","iopub.status.idle":"2025-10-14T18:14:43.411265Z","shell.execute_reply.started":"2025-10-14T18:14:17.466714Z","shell.execute_reply":"2025-10-14T18:14:43.410642Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('json', data_files={\n    'train': '/kaggle/working/train.jsonl',\n    'test': '/kaggle/working/test.jsonl'\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:14:43.412060Z","iopub.execute_input":"2025-10-14T18:14:43.412330Z","iopub.status.idle":"2025-10-14T18:14:51.950931Z","shell.execute_reply.started":"2025-10-14T18:14:43.412301Z","shell.execute_reply":"2025-10-14T18:14:51.950158Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f60a346a3c7f455286fcde085fbf8ec2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4a71244739f42a7bba20b9e5d0e814c"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:14:51.951696Z","iopub.execute_input":"2025-10-14T18:14:51.952015Z","iopub.status.idle":"2025-10-14T18:14:51.959960Z","shell.execute_reply.started":"2025-10-14T18:14:51.951996Z","shell.execute_reply":"2025-10-14T18:14:51.959192Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'id': 'X51007231344',\n 'image': '/kaggle/input/recipts-data/dataset/train/img/X51007231344.jpg',\n 'words': ['UNIHAKKA INTERNATIONAL SDN BHD',\n  '05 MAY 2018 18:21',\n  '(867388-U)',\n  '12, JALAN TAMPOI 7/4,KAWASAN PERINDUSTRIAN',\n  'TAMPOI,81200 JOHOR BAHRU,JOHOR',\n  'TAXINVOICE',\n  'INVOICE # : OR18050502160248',\n  'ITEM',\n  'QTY',\n  'TOTAL',\n  'SR I00100000035- 1 MEAT + 3 VEGE',\n  '$7.10',\n  '1',\n  '$7.10',\n  'SR I00100000170- IMPORTED VEGGIES',\n  '$1.60',\n  '1',\n  '$1.60',\n  'SR I00100000099- COKE',\n  '$2.50',\n  '1',\n  '$2.50',\n  'TOTAL AMOUNT: $11.20',\n  'GST @6%: $0.63',\n  'NETT TOTAL: $11.20',\n  'PAYMENT MODE',\n  'AMOUNT',\n  'CASH',\n  '$11.20',\n  'CHANGE',\n  '$0.00',\n  'GST SUMMARY',\n  'AMOUNT($)',\n  'TAX($)',\n  'SR = GST @6%',\n  '10.57',\n  '0.63',\n  'GST REG #000656195584',\n  'BAR WANG RICE@PERMAS JAYA',\n  '(PRICE INCLUSIVE OF GST)',\n  'THANK YOU & COME AGAIN!',\n  'LIKE AND FOLLOW US ON FACEBOOK!',\n  'FACEBOOK.COM/BARWANGRICE'],\n 'boxes': [[336, 195, 606, 204],\n  [420, 206, 521, 214],\n  [440, 217, 503, 227],\n  [355, 229, 587, 238],\n  [382, 241, 559, 250],\n  [430, 251, 510, 261],\n  [323, 263, 490, 273],\n  [323, 281, 347, 289],\n  [417, 281, 437, 290],\n  [590, 279, 619, 290],\n  [324, 294, 516, 304],\n  [323, 306, 354, 316],\n  [417, 308, 426, 316],\n  [586, 306, 618, 315],\n  [323, 324, 521, 334],\n  [323, 337, 353, 347],\n  [417, 339, 424, 348],\n  [586, 337, 617, 348],\n  [322, 355, 456, 364],\n  [322, 367, 355, 378],\n  [417, 369, 424, 377],\n  [586, 367, 618, 377],\n  [503, 389, 616, 399],\n  [524, 400, 618, 410],\n  [522, 412, 616, 421],\n  [322, 429, 401, 438],\n  [574, 428, 617, 438],\n  [322, 443, 357, 451],\n  [578, 442, 616, 451],\n  [323, 454, 364, 465],\n  [583, 453, 615, 463],\n  [322, 483, 390, 493],\n  [473, 483, 521, 492],\n  [586, 483, 616, 492],\n  [322, 497, 392, 505],\n  [495, 497, 520, 504],\n  [596, 497, 616, 505],\n  [396, 514, 538, 523],\n  [372, 525, 565, 536],\n  [402, 537, 530, 549],\n  [396, 549, 537, 559],\n  [379, 561, 554, 570],\n  [390, 572, 543, 583]],\n 'labels': ['B-COMPANY',\n  'B-DATE',\n  'O',\n  'B-ADDRESS',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'B-TOTAL',\n  'O',\n  'B-TOTAL',\n  'O',\n  'O',\n  'O',\n  'B-TOTAL',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O',\n  'O']}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification\nfrom transformers import TrainingArguments, Trainer\nfrom seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:14:51.960622Z","iopub.execute_input":"2025-10-14T18:14:51.960827Z","iopub.status.idle":"2025-10-14T18:15:21.599942Z","shell.execute_reply.started":"2025-10-14T18:14:51.960811Z","shell.execute_reply":"2025-10-14T18:15:21.599350Z"}},"outputs":[{"name":"stderr","text":"2025-10-14 18:15:00.197398: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760465700.639140      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760465700.773299      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n\nlabels = sorted({l for ex in dataset['train'] for l in ex['labels']})\nid2label = {i: label for i, label in enumerate(labels)}\nlabel2id = {label: i for i, label in enumerate(labels)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:15:21.602339Z","iopub.execute_input":"2025-10-14T18:15:21.602912Z","iopub.status.idle":"2025-10-14T18:15:23.333564Z","shell.execute_reply.started":"2025-10-14T18:15:21.602890Z","shell.execute_reply":"2025-10-14T18:15:23.332950Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/275 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f505c166cd84e228e502ae061a6eeb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c00cec50b8a040338368c67b8aa2ed6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe4ebca266f240c8b9f33476dfd9b3df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d470de7a56e94bcd81cb82e17fa68b46"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"id2label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:15:23.334250Z","iopub.execute_input":"2025-10-14T18:15:23.334434Z","iopub.status.idle":"2025-10-14T18:15:23.339821Z","shell.execute_reply.started":"2025-10-14T18:15:23.334419Z","shell.execute_reply":"2025-10-14T18:15:23.338906Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{0: 'B-ADDRESS', 1: 'B-COMPANY', 2: 'B-DATE', 3: 'B-TOTAL', 4: 'O'}"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"label2id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:15:23.340563Z","iopub.execute_input":"2025-10-14T18:15:23.340867Z","iopub.status.idle":"2025-10-14T18:15:23.367264Z","shell.execute_reply.started":"2025-10-14T18:15:23.340843Z","shell.execute_reply":"2025-10-14T18:15:23.366557Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'B-ADDRESS': 0, 'B-COMPANY': 1, 'B-DATE': 2, 'B-TOTAL': 3, 'O': 4}"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"model = LayoutLMv3ForTokenClassification.from_pretrained(\n    \"microsoft/layoutlmv3-base\",\n    num_labels=len(labels),\n    id2label=id2label,\n    label2id=label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:15:23.367883Z","iopub.execute_input":"2025-10-14T18:15:23.368093Z","iopub.status.idle":"2025-10-14T18:15:27.034428Z","shell.execute_reply.started":"2025-10-14T18:15:23.368072Z","shell.execute_reply":"2025-10-14T18:15:27.033634Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/856 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"540e7ebe8b2e4b79b446a78481b9a82a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1709d55f00874fac80ad9d4a1659885f"}},"metadata":{}},{"name":"stderr","text":"Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def preprocess(example):\n    image = Image.open(example['image']).convert(\"RGB\")\n\n    encoding = processor(\n        image,\n        boxes=example['boxes'],\n        text=example['words'],\n        word_labels=[label2id[l] for l in example['labels']],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=512,\n        return_tensors=\"pt\"\n    )\n\n    return {k: v.squeeze() for k, v in encoding.items()}\n\nencoded_dataset = dataset.map(preprocess, remove_columns=dataset['train'].column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:15:27.035288Z","iopub.execute_input":"2025-10-14T18:15:27.035745Z","iopub.status.idle":"2025-10-14T18:17:34.578425Z","shell.execute_reply.started":"2025-10-14T18:15:27.035725Z","shell.execute_reply":"2025-10-14T18:17:34.577577Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/626 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79e9e1ad08b2457b8bc40b88440f7152"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/347 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"090fb78b4aad4db38b552dd4332d2f14"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:17:34.579469Z","iopub.execute_input":"2025-10-14T18:17:34.579779Z","iopub.status.idle":"2025-10-14T18:17:34.584079Z","shell.execute_reply.started":"2025-10-14T18:17:34.579752Z","shell.execute_reply":"2025-10-14T18:17:34.583177Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nfrom seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n\ndef compute_metrics(pred):\n    predictions, labels = pred\n    predictions = np.argmax(predictions, axis=2)\n\n    true_predictions = [\n        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    return {\n        \"precision\": precision_score(true_labels, true_predictions),\n        \"recall\": recall_score(true_labels, true_predictions),\n        \"f1\": f1_score(true_labels, true_predictions),\n        \"accuracy\": accuracy_score(true_labels, true_predictions),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:17:34.584892Z","iopub.execute_input":"2025-10-14T18:17:34.585269Z","iopub.status.idle":"2025-10-14T18:17:35.393756Z","shell.execute_reply.started":"2025-10-14T18:17:34.585244Z","shell.execute_reply":"2025-10-14T18:17:35.393028Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:18:33.435093Z","iopub.execute_input":"2025-10-14T18:18:33.435751Z","iopub.status.idle":"2025-10-14T18:18:33.457860Z","shell.execute_reply.started":"2025-10-14T18:18:33.435718Z","shell.execute_reply":"2025-10-14T18:18:33.456819Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adc89a4297fc48f681aa44ea6a782420"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"/kaggle/working/layoutlmv3-receipts\",\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    learning_rate=1e-5,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_steps=5,\n    fp16=True,\n    disable_tqdm=False,\n    report_to=\"none\",\n    push_to_hub=True,\n    hub_model_id=\"Sameed1/smdk-layoutlmv3-receipts\",\n    hub_strategy=\"end\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:18:53.364053Z","iopub.execute_input":"2025-10-14T18:18:53.364326Z","iopub.status.idle":"2025-10-14T18:18:53.398209Z","shell.execute_reply.started":"2025-10-14T18:18:53.364306Z","shell.execute_reply":"2025-10-14T18:18:53.397383Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_dataset[\"train\"],\n    eval_dataset=encoded_dataset[\"test\"],\n    tokenizer=processor.tokenizer,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:18:57.115337Z","iopub.execute_input":"2025-10-14T18:18:57.115638Z","iopub.status.idle":"2025-10-14T18:27:25.736615Z","shell.execute_reply.started":"2025-10-14T18:18:57.115587Z","shell.execute_reply":"2025-10-14T18:27:25.735921Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_37/1184037775.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [471/471 08:23, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>1.564500</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.707100</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.489600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.408000</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.377100</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.340700</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.297900</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.244200</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.244500</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.222200</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.203000</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.179900</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.175700</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.154700</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.140400</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.148100</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.134500</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.153300</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.116100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.141800</td>\n    </tr>\n    <tr>\n      <td>105</td>\n      <td>0.105400</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.102400</td>\n    </tr>\n    <tr>\n      <td>115</td>\n      <td>0.101800</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.096700</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.086900</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.081500</td>\n    </tr>\n    <tr>\n      <td>135</td>\n      <td>0.098200</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.093100</td>\n    </tr>\n    <tr>\n      <td>145</td>\n      <td>0.100500</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.105000</td>\n    </tr>\n    <tr>\n      <td>155</td>\n      <td>0.069600</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.125100</td>\n    </tr>\n    <tr>\n      <td>165</td>\n      <td>0.091400</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.109900</td>\n    </tr>\n    <tr>\n      <td>175</td>\n      <td>0.095900</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.108300</td>\n    </tr>\n    <tr>\n      <td>185</td>\n      <td>0.109200</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.041000</td>\n    </tr>\n    <tr>\n      <td>195</td>\n      <td>0.077200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.076200</td>\n    </tr>\n    <tr>\n      <td>205</td>\n      <td>0.071500</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.064900</td>\n    </tr>\n    <tr>\n      <td>215</td>\n      <td>0.082800</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.111500</td>\n    </tr>\n    <tr>\n      <td>225</td>\n      <td>0.060700</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.059100</td>\n    </tr>\n    <tr>\n      <td>235</td>\n      <td>0.061700</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.044600</td>\n    </tr>\n    <tr>\n      <td>245</td>\n      <td>0.049700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.061000</td>\n    </tr>\n    <tr>\n      <td>255</td>\n      <td>0.048400</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.065700</td>\n    </tr>\n    <tr>\n      <td>265</td>\n      <td>0.050400</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.064500</td>\n    </tr>\n    <tr>\n      <td>275</td>\n      <td>0.051000</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.058500</td>\n    </tr>\n    <tr>\n      <td>285</td>\n      <td>0.054500</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.057800</td>\n    </tr>\n    <tr>\n      <td>295</td>\n      <td>0.082400</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.059400</td>\n    </tr>\n    <tr>\n      <td>305</td>\n      <td>0.094200</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.053600</td>\n    </tr>\n    <tr>\n      <td>315</td>\n      <td>0.053800</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.055700</td>\n    </tr>\n    <tr>\n      <td>325</td>\n      <td>0.053500</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.024300</td>\n    </tr>\n    <tr>\n      <td>335</td>\n      <td>0.066600</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.055700</td>\n    </tr>\n    <tr>\n      <td>345</td>\n      <td>0.061400</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.063900</td>\n    </tr>\n    <tr>\n      <td>355</td>\n      <td>0.039700</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.050100</td>\n    </tr>\n    <tr>\n      <td>365</td>\n      <td>0.057400</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.058300</td>\n    </tr>\n    <tr>\n      <td>375</td>\n      <td>0.038600</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.059300</td>\n    </tr>\n    <tr>\n      <td>385</td>\n      <td>0.048700</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.052700</td>\n    </tr>\n    <tr>\n      <td>395</td>\n      <td>0.037900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.047000</td>\n    </tr>\n    <tr>\n      <td>405</td>\n      <td>0.051200</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.043000</td>\n    </tr>\n    <tr>\n      <td>415</td>\n      <td>0.039800</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.043400</td>\n    </tr>\n    <tr>\n      <td>425</td>\n      <td>0.042000</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.073800</td>\n    </tr>\n    <tr>\n      <td>435</td>\n      <td>0.041300</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.068600</td>\n    </tr>\n    <tr>\n      <td>445</td>\n      <td>0.032500</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.052500</td>\n    </tr>\n    <tr>\n      <td>455</td>\n      <td>0.057600</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.045700</td>\n    </tr>\n    <tr>\n      <td>465</td>\n      <td>0.033000</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.044900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=471, training_loss=0.12025927238941446, metrics={'train_runtime': 508.0948, 'train_samples_per_second': 3.696, 'train_steps_per_second': 0.927, 'total_flos': 495041961535488.0, 'train_loss': 0.12025927238941446, 'epoch': 3.0})"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"eval_results = trainer.evaluate()\neval_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:27:38.245374Z","iopub.execute_input":"2025-10-14T18:27:38.246048Z","iopub.status.idle":"2025-10-14T18:28:38.871682Z","shell.execute_reply.started":"2025-10-14T18:27:38.246023Z","shell.execute_reply":"2025-10-14T18:28:38.871025Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:1621: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [87/87 00:59]\n    </div>\n    "},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.059942491352558136,\n 'eval_precision': 0.8875767595654228,\n 'eval_recall': 0.9446958270487682,\n 'eval_f1': 0.9152459814905016,\n 'eval_accuracy': 0.9817569013481703,\n 'eval_runtime': 60.6166,\n 'eval_samples_per_second': 5.725,\n 'eval_steps_per_second': 1.435,\n 'epoch': 3.0}"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:33:20.502151Z","iopub.execute_input":"2025-10-14T18:33:20.502441Z","iopub.status.idle":"2025-10-14T18:33:20.518342Z","shell.execute_reply.started":"2025-10-14T18:33:20.502415Z","shell.execute_reply":"2025-10-14T18:33:20.517316Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b272de8cb2a3464c8268fe0da662dd10"}},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"trained_model = LayoutLMv3ForTokenClassification.from_pretrained(\"/kaggle/working/layoutlmv3-receipts/checkpoint-471\")\ntrained_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:32:52.064761Z","iopub.execute_input":"2025-10-14T18:32:52.065875Z","iopub.status.idle":"2025-10-14T18:32:52.159936Z","shell.execute_reply.started":"2025-10-14T18:32:52.065835Z","shell.execute_reply":"2025-10-14T18:32:52.159156Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"LayoutLMv3ForTokenClassification(\n  (layoutlmv3): LayoutLMv3Model(\n    (embeddings): LayoutLMv3TextEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (x_position_embeddings): Embedding(1024, 128)\n      (y_position_embeddings): Embedding(1024, 128)\n      (h_position_embeddings): Embedding(1024, 128)\n      (w_position_embeddings): Embedding(1024, 128)\n    )\n    (patch_embed): LayoutLMv3PatchEmbeddings(\n      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (pos_drop): Dropout(p=0.0, inplace=False)\n    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n    (encoder): LayoutLMv3Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x LayoutLMv3Layer(\n          (attention): LayoutLMv3Attention(\n            (self): LayoutLMv3SelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): LayoutLMv3SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): LayoutLMv3Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): LayoutLMv3Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_pos_bias): Linear(in_features=32, out_features=12, bias=False)\n      (rel_pos_x_bias): Linear(in_features=64, out_features=12, bias=False)\n      (rel_pos_y_bias): Linear(in_features=64, out_features=12, bias=False)\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=5, bias=True)\n)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"trained_model.push_to_hub(\"smdk-layoutlmv3-receipts\")\nprocessor.push_to_hub(\"smdk-layoutlmv3-receipts\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T18:35:48.300491Z","iopub.execute_input":"2025-10-14T18:35:48.301134Z","iopub.status.idle":"2025-10-14T18:35:54.390417Z","shell.execute_reply.started":"2025-10-14T18:35:48.301112Z","shell.execute_reply":"2025-10-14T18:35:54.389854Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a6974d828a240b69ae6d701c68a83a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"703d7d13d3e54936b79dce22900e9919"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\nNo files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Sameed1/smdk-layoutlmv3-receipts/commit/00c94defe5f7ab52aab476263ff8a7b5593d2d6c', commit_message='Upload processor', commit_description='', oid='00c94defe5f7ab52aab476263ff8a7b5593d2d6c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Sameed1/smdk-layoutlmv3-receipts', endpoint='https://huggingface.co', repo_type='model', repo_id='Sameed1/smdk-layoutlmv3-receipts'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":28}]}